{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Archivist is an easy-to-use application that brings AI chat capabilities to your personal computer without requiring internet access. What makes Archivist special is its ability to learn from your own files and documents. Simply upload any files you want\u2014like PDFs, Word documents, or text files\u2014and Archivist makes their content available during your AI conversations. You can ask questions about specific documents or across your entire collection, getting insightful answers based on your personal information. No technical knowledge required\u2014just upload your files, ask questions, and get smart responses that draw directly from your own curated library of documents. This application serves as a capability demonstration rather than a finished product. As system integrators specializing in AI solutions for professional services firms, developing mass-market desktop applications isn't our core business model. We've made deliberate packaging decisions that prioritize demonstrability over startup speed. The application wraps what would typically be an always-on network service into a distributable format you can try on your own hardware. There is an inherent speed tradeoff with this approach. Query Tab Pre-Process Tab Upload Tab Browse Tab Inspect Tab AI Settings Tab Help and Licensing Tab Value Proposition Local/private/secure [[Retrieval Augmented Generation|RAG]] application for individual users Fully functional at no cost No subscription fees No service outages No chat limits Easy setup Low cost one-time paid [[Licensing]] option to enable users to upload custom LLMs Support [[Open Source]] Powered by commercial-grade AI technology by [[IBM]] Makes your data [[Data Portability|portable]] for other AI applications Runs on a laptop Cost advantage over time No ongoing subscription fees to ChatGPT Plus ($20/month), Claude Pro ($20/month), etc. One-time payment vs. potentially hundreds of dollars per year Clear ROI after just a few months compared to commercial AI subscriptions Reliability and independence Works offline, including in areas with poor internet Not subject to API rate limits or service outages No need to worry about price increases Resource efficiency Optimized for their specific use case Better performance on targeted tasks than general-purpose AI Faster responses for document-specific questions Feature Overview Your personal, purpose-built, [[Retrieval Augmented Generation]] application Uses metadata filtering to enable you to precisely control which information the AI considers\u2014whether you want answers from a specific individual document, a curated collection of related files ([[File Sets]]), or your entire knowledge base\u2014ensuring your conversations remain focused on exactly the information that matters to your current task. Simple AI chat with a local LLM Voice input so you can dictate your messages Pre-processing text Infinitely flexible text chunking strategies Simple import/export to improve [[Data Portability]] and reduce vendor lock-in Explore the power of private data intelligence with our showcase application! This demonstration highlights our expertise in: Seamless ingestion of your proprietary documents Intelligent chunking and vector embedding Optimized retrieval with contextual awareness Natural language generation grounded in your data Secure, local processing for sensitive information","title":"Home"},{"location":"#value-proposition","text":"Local/private/secure [[Retrieval Augmented Generation|RAG]] application for individual users Fully functional at no cost No subscription fees No service outages No chat limits Easy setup Low cost one-time paid [[Licensing]] option to enable users to upload custom LLMs Support [[Open Source]] Powered by commercial-grade AI technology by [[IBM]] Makes your data [[Data Portability|portable]] for other AI applications Runs on a laptop Cost advantage over time No ongoing subscription fees to ChatGPT Plus ($20/month), Claude Pro ($20/month), etc. One-time payment vs. potentially hundreds of dollars per year Clear ROI after just a few months compared to commercial AI subscriptions Reliability and independence Works offline, including in areas with poor internet Not subject to API rate limits or service outages No need to worry about price increases Resource efficiency Optimized for their specific use case Better performance on targeted tasks than general-purpose AI Faster responses for document-specific questions","title":"Value Proposition"},{"location":"#feature-overview","text":"Your personal, purpose-built, [[Retrieval Augmented Generation]] application Uses metadata filtering to enable you to precisely control which information the AI considers\u2014whether you want answers from a specific individual document, a curated collection of related files ([[File Sets]]), or your entire knowledge base\u2014ensuring your conversations remain focused on exactly the information that matters to your current task. Simple AI chat with a local LLM Voice input so you can dictate your messages Pre-processing text Infinitely flexible text chunking strategies Simple import/export to improve [[Data Portability]] and reduce vendor lock-in Explore the power of private data intelligence with our showcase application! This demonstration highlights our expertise in: Seamless ingestion of your proprietary documents Intelligent chunking and vector embedding Optimized retrieval with contextual awareness Natural language generation grounded in your data Secure, local processing for sensitive information","title":"Feature Overview"},{"location":"tabs/ai_settings/","text":"Overview The AI Settings Tab puts you in control of how Archivist's artificial intelligence operates, allowing you to tailor the system to your specific needs and preferences. This powerful customization center is organized into three intuitive sections, each addressing a different aspect of the AI's behavior. Here you can adjust everything from which AI model powers your conversations to how it interprets your questions and what specialized knowledge it brings to your interactions. Whether you're looking for casual assistance or need precise, technical responses, the AI Settings Tab lets you configure Archivist to work exactly the way you want it to. These settings directly influence how the AI responds in your chats, making this tab essential for users who want to optimize their experience. From basic model selection to advanced prompting strategies, the three configuration cards in this tab give you comprehensive control over your AI assistant's capabilities and personality. Details Model Selection and Configuration Options Default Models Archivist provides a thoughtfully curated AI experience built around the versatile IBM Granite 3.2 2B model. This lightweight yet powerful model is specifically chosen to run smoothly on standard laptops and computers without requiring specialized GPU hardware, making advanced AI accessible to everyday business users. When you first install Archivist, you'll find two model options available: IBM Granite 3.2 2B (Standard) The default configuration with balanced performance Ready for general queries and document-based conversations Pre-optimized settings for most business use cases IBM Granite 3.2 2B by Integral Business Intelligence The same core model but with the \"IBM Granite Advanced Configuration\" applied Allows you to personalize how the AI interprets requests and formulates responses Created automatically when you modify prompt settings Both of these initial models are protected and cannot be deleted, ensuring you always have a functioning baseline AI experience. Paid License Model Features For paid license holders, Archivist unlocks additional model management capabilities: Upload compatible models specific to your industry or use case Manage your model collection as your needs evolve Delete custom models when no longer needed (while core models remain protected) This approach gives you both simplicity and flexibility\u2014start working immediately with optimized defaults, then customize as you become more familiar with your specific needs. Model Registry/Management \u26a0\ufe0f Important: Model Management Guidelines Using AI Models in the Application This application uses a secure model registry system to manage AI models. For the best experience and to avoid errors, please follow these guidelines: Do Not Manually Modify Model Files Do not manually add model files to the application directories. Models added outside the application interface will not be recognized or function properly. Do not manually delete or modify model files from application directories. This can cause errors and potentially corrupt the application. Proper Model Management Always use the application interface to upload new models (requires a premium license). Always use the application's delete function to remove models you no longer need. If you encounter an error indicating a model is missing, use the application's repair or refresh function to resolve this issue. Why These Guidelines Matter Our application uses a secure registration system that keeps track of your installed models. This system ensures: Your models remain available after application updates Only properly validated models are used The integrity of your application installation is maintained Bypassing this system by manually manipulating files will lead to errors that may prevent the application from functioning correctly. Thank you for helping us maintain a stable and secure environment for your AI workflows. Model Parameters Context Length Adjust the maximum context length (in tokens) that the AI model can process at once. This controls how much information the model can consider when generating responses. A larger context length allows for more comprehensive understanding of complex queries and documents, but requires more system RAM. Adjust this setting based on your computer's capabilities and the complexity of your typical conversations. Embedding Model Context Length This setting determines the maximum size of text chunks that can be processed when embedding documents into your database. If you plan to use large chunk sizes during document upload, ensure this value is set high enough to accommodate them. If the embedding context length is smaller than your chosen chunk size, the upload operation will not complete successfully (which is a good thing, instead of silently truncating information). Balance this against your system's memory constraints for optimal performance. Temperature Control the creativity and variability of the AI's responses with the temperature setting. Lower values (closer to 0) produce more deterministic, focused responses that stick closely to the most probable outputs. Higher values (closer to 1) introduce more randomness, creativity, and exploration in the responses. Professional users typically prefer lower temperatures for factual consistency, while creative applications might benefit from higher settings. Number of RAG Chunks Specify exactly how many relevant text chunks from your database will be provided to the AI model during RAG conversations. This important setting balances comprehensiveness against focus: higher numbers give the AI more potential information to work with but may introduce noise, while lower numbers keep responses tightly focused on the most relevant information. Archivist selects the most semantically similar chunks to your query, up to this specified limit. Citations Toggle When enabled, this feature adds transparent source references to AI responses in RAG mode, showing exactly which files and chunk numbers contributed to each answer. Citations appear at the end of the response, allowing you to verify information against your original documents. This powerful [[Transparency]] feature is especially valuable in professional contexts where accountability and fact-checking are important, giving you confidence in the AI's responses by making its information sources explicit. Prompt Configuration The Prompt Configuration card gives you precise control over how the AI interprets your requests and formulates its responses. At its center is a customizable text area where you can craft your system prompt\u2014the foundational instructions that shape the AI's understanding of its role and responsibilities. System Prompt This primary text field is where you define the AI's personality, knowledge focus, response style, and operational parameters. A well-crafted system prompt can dramatically improve the relevance and quality of your AI interactions. For example, you might instruct the AI to focus on academic writing, to prioritize brevity, or to emphasize practical business applications in its responses. Special Token Controls For advanced users and specialized models, Archivist provides four optional input fields that allow you to insert specific tokens at critical positions in the conversation flow: Before System Prompt: Special tokens that signal the beginning of system instructions After System Prompt: Tokens that mark the transition from system instructions to conversation Before User Message: Tokens that indicate when a user input begins After User Message: Tokens that signal the end of user input These token fields accommodate the technical requirements of various AI models, which may use specific markers to properly interpret different parts of the conversation. While not needed for most standard interactions, these options ensure compatibility with specialized models that require particular formatting. Scope of Application The system prompt and special tokens configured here apply to all models in your Archivist installation, with one exception: the \"IBM Granite 3.2 2B by Integral Business Intelligence\" model. That model instead uses the specialized configuration from the IBM Granite Advanced Configuration card, giving you two separate prompt frameworks to work with. This flexibility allows you to maintain a general prompt setup for most models while taking advantage of Granite's unique capabilities through its dedicated advanced configuration. IBM Granite Advanced Configuration What makes IBM Granite particularly valuable is its ability to operate in different specialized modes\u2014capabilities that typically require complex prompt engineering to access. Archivist makes these advanced features available through simple button selections: Operation Modes: - Standard Chat Mode: General conversation and information - RAG Mode: Focused on retrieving and using information from your documents - Reasoning Mode: Enhanced critical thinking for complex questions Response Length Controls: - Normal: Balanced information density - Short: Concise, to-the-point answers - Long: Comprehensive, detailed explanations RAG Response Styles (when in RAG Mode): - Default: Balanced approach to using your documents - Extractive: Near-direct quotes from your source materials - Abstractive: Paraphrased summaries that capture key concepts After selecting your preferred configuration, clicking \"Save Granite Configuration\" applies these settings to the \"IBM Granite 3.2 2B by Integral Business Intelligence\" option in your model selection dropdown. See Also [[IBM]]","title":"AI Settings Tab"},{"location":"tabs/ai_settings/#overview","text":"The AI Settings Tab puts you in control of how Archivist's artificial intelligence operates, allowing you to tailor the system to your specific needs and preferences. This powerful customization center is organized into three intuitive sections, each addressing a different aspect of the AI's behavior. Here you can adjust everything from which AI model powers your conversations to how it interprets your questions and what specialized knowledge it brings to your interactions. Whether you're looking for casual assistance or need precise, technical responses, the AI Settings Tab lets you configure Archivist to work exactly the way you want it to. These settings directly influence how the AI responds in your chats, making this tab essential for users who want to optimize their experience. From basic model selection to advanced prompting strategies, the three configuration cards in this tab give you comprehensive control over your AI assistant's capabilities and personality.","title":"Overview"},{"location":"tabs/ai_settings/#details","text":"","title":"Details"},{"location":"tabs/ai_settings/#model-selection-and-configuration-options","text":"","title":"Model Selection and Configuration Options"},{"location":"tabs/ai_settings/#default-models","text":"Archivist provides a thoughtfully curated AI experience built around the versatile IBM Granite 3.2 2B model. This lightweight yet powerful model is specifically chosen to run smoothly on standard laptops and computers without requiring specialized GPU hardware, making advanced AI accessible to everyday business users. When you first install Archivist, you'll find two model options available: IBM Granite 3.2 2B (Standard) The default configuration with balanced performance Ready for general queries and document-based conversations Pre-optimized settings for most business use cases IBM Granite 3.2 2B by Integral Business Intelligence The same core model but with the \"IBM Granite Advanced Configuration\" applied Allows you to personalize how the AI interprets requests and formulates responses Created automatically when you modify prompt settings Both of these initial models are protected and cannot be deleted, ensuring you always have a functioning baseline AI experience.","title":"Default Models"},{"location":"tabs/ai_settings/#paid-license-model-features","text":"For paid license holders, Archivist unlocks additional model management capabilities: Upload compatible models specific to your industry or use case Manage your model collection as your needs evolve Delete custom models when no longer needed (while core models remain protected) This approach gives you both simplicity and flexibility\u2014start working immediately with optimized defaults, then customize as you become more familiar with your specific needs.","title":"Paid License Model Features"},{"location":"tabs/ai_settings/#model-registrymanagement","text":"\u26a0\ufe0f Important: Model Management Guidelines Using AI Models in the Application This application uses a secure model registry system to manage AI models. For the best experience and to avoid errors, please follow these guidelines: Do Not Manually Modify Model Files Do not manually add model files to the application directories. Models added outside the application interface will not be recognized or function properly. Do not manually delete or modify model files from application directories. This can cause errors and potentially corrupt the application. Proper Model Management Always use the application interface to upload new models (requires a premium license). Always use the application's delete function to remove models you no longer need. If you encounter an error indicating a model is missing, use the application's repair or refresh function to resolve this issue. Why These Guidelines Matter Our application uses a secure registration system that keeps track of your installed models. This system ensures: Your models remain available after application updates Only properly validated models are used The integrity of your application installation is maintained Bypassing this system by manually manipulating files will lead to errors that may prevent the application from functioning correctly. Thank you for helping us maintain a stable and secure environment for your AI workflows.","title":"Model Registry/Management"},{"location":"tabs/ai_settings/#model-parameters","text":"","title":"Model Parameters"},{"location":"tabs/ai_settings/#context-length","text":"Adjust the maximum context length (in tokens) that the AI model can process at once. This controls how much information the model can consider when generating responses. A larger context length allows for more comprehensive understanding of complex queries and documents, but requires more system RAM. Adjust this setting based on your computer's capabilities and the complexity of your typical conversations.","title":"Context Length"},{"location":"tabs/ai_settings/#embedding-model-context-length","text":"This setting determines the maximum size of text chunks that can be processed when embedding documents into your database. If you plan to use large chunk sizes during document upload, ensure this value is set high enough to accommodate them. If the embedding context length is smaller than your chosen chunk size, the upload operation will not complete successfully (which is a good thing, instead of silently truncating information). Balance this against your system's memory constraints for optimal performance.","title":"Embedding Model Context Length"},{"location":"tabs/ai_settings/#temperature","text":"Control the creativity and variability of the AI's responses with the temperature setting. Lower values (closer to 0) produce more deterministic, focused responses that stick closely to the most probable outputs. Higher values (closer to 1) introduce more randomness, creativity, and exploration in the responses. Professional users typically prefer lower temperatures for factual consistency, while creative applications might benefit from higher settings.","title":"Temperature"},{"location":"tabs/ai_settings/#number-of-rag-chunks","text":"Specify exactly how many relevant text chunks from your database will be provided to the AI model during RAG conversations. This important setting balances comprehensiveness against focus: higher numbers give the AI more potential information to work with but may introduce noise, while lower numbers keep responses tightly focused on the most relevant information. Archivist selects the most semantically similar chunks to your query, up to this specified limit.","title":"Number of RAG Chunks"},{"location":"tabs/ai_settings/#citations-toggle","text":"When enabled, this feature adds transparent source references to AI responses in RAG mode, showing exactly which files and chunk numbers contributed to each answer. Citations appear at the end of the response, allowing you to verify information against your original documents. This powerful [[Transparency]] feature is especially valuable in professional contexts where accountability and fact-checking are important, giving you confidence in the AI's responses by making its information sources explicit.","title":"Citations Toggle"},{"location":"tabs/ai_settings/#prompt-configuration","text":"The Prompt Configuration card gives you precise control over how the AI interprets your requests and formulates its responses. At its center is a customizable text area where you can craft your system prompt\u2014the foundational instructions that shape the AI's understanding of its role and responsibilities.","title":"Prompt Configuration"},{"location":"tabs/ai_settings/#system-prompt","text":"This primary text field is where you define the AI's personality, knowledge focus, response style, and operational parameters. A well-crafted system prompt can dramatically improve the relevance and quality of your AI interactions. For example, you might instruct the AI to focus on academic writing, to prioritize brevity, or to emphasize practical business applications in its responses.","title":"System Prompt"},{"location":"tabs/ai_settings/#special-token-controls","text":"For advanced users and specialized models, Archivist provides four optional input fields that allow you to insert specific tokens at critical positions in the conversation flow: Before System Prompt: Special tokens that signal the beginning of system instructions After System Prompt: Tokens that mark the transition from system instructions to conversation Before User Message: Tokens that indicate when a user input begins After User Message: Tokens that signal the end of user input These token fields accommodate the technical requirements of various AI models, which may use specific markers to properly interpret different parts of the conversation. While not needed for most standard interactions, these options ensure compatibility with specialized models that require particular formatting.","title":"Special Token Controls"},{"location":"tabs/ai_settings/#scope-of-application","text":"The system prompt and special tokens configured here apply to all models in your Archivist installation, with one exception: the \"IBM Granite 3.2 2B by Integral Business Intelligence\" model. That model instead uses the specialized configuration from the IBM Granite Advanced Configuration card, giving you two separate prompt frameworks to work with. This flexibility allows you to maintain a general prompt setup for most models while taking advantage of Granite's unique capabilities through its dedicated advanced configuration.","title":"Scope of Application"},{"location":"tabs/ai_settings/#ibm-granite-advanced-configuration","text":"What makes IBM Granite particularly valuable is its ability to operate in different specialized modes\u2014capabilities that typically require complex prompt engineering to access. Archivist makes these advanced features available through simple button selections: Operation Modes: - Standard Chat Mode: General conversation and information - RAG Mode: Focused on retrieving and using information from your documents - Reasoning Mode: Enhanced critical thinking for complex questions Response Length Controls: - Normal: Balanced information density - Short: Concise, to-the-point answers - Long: Comprehensive, detailed explanations RAG Response Styles (when in RAG Mode): - Default: Balanced approach to using your documents - Extractive: Near-direct quotes from your source materials - Abstractive: Paraphrased summaries that capture key concepts After selecting your preferred configuration, clicking \"Save Granite Configuration\" applies these settings to the \"IBM Granite 3.2 2B by Integral Business Intelligence\" option in your model selection dropdown.","title":"IBM Granite Advanced Configuration"},{"location":"tabs/ai_settings/#see-also","text":"[[IBM]]","title":"See Also"},{"location":"tabs/browse/","text":"Overview The Browse Tab serves as your file management center, providing a clear view of all files currently stored in your Archivist database. Once you've uploaded documents through the Upload Tab, this interface allows you to see your complete knowledge collection at a glance. Here you can explore your files and manage your personal knowledge base. The Browse Tab gives you visibility into exactly what information the AI can access when answering your questions, helping you maintain an organized and effective document collection. Details File Information Display When you load files from your database, they appear in an organized data frame showing important details about each document\u2014including filename, number of chunks created, and which file sets each document belongs to. This at-a-glance view helps you understand how your knowledge base is structured. Search and Filter Located above the data frame, a filter option lets you quickly locate specific files by typing part of a filename. As you type, the display automatically narrows to show only matching documents, making it easy to find exactly what you need in larger collections. File Selection and Operations Click on any row in the data frame to select an individual file. Once selected, you can perform various operations using the buttons at the bottom of the tab: Open Selected File Button This valuable feature opens the original source document that was uploaded to Archivist. When you upload files, Archivist automatically stores a copy of the original in your user data directory. This means you can always reference the complete, original document to verify information or check context when reviewing AI responses. This [[Transparency]] allows you to easily validate answers against their source material with just a click. Open Docs Folder Button This convenient shortcut opens the system folder containing all your source documents. Instead of navigating through numerous directories to find your files, this button takes you directly to the location where Archivist stores all original document copies. This makes it easy to access, organize, or back up your entire document collection at once, saving you time when you need to work with multiple files outside of Archivist. Clean Up Orphaned Files Button Sometimes files may appear in your documents folder without properly associated database entries\u2014perhaps from manually copying files to the directory or from interrupted processing operations. The Clean Up button scans your document directory for these \"orphaned\" files (source documents that don't have corresponding chunks in the database) and removes them. This maintenance feature helps keep your document storage clean and properly synchronized with the database, ensuring everything you see is fully functional within Archivist. Delete Selected File Button When you need to remove a document from your knowledge base, select it in the data frame and click this button. Archivist thoroughly cleans up by removing both the original source document from your docs folder and all associated text chunks from the database. This complete removal ensures no fragments remain to potentially appear in future AI responses, giving you full control over exactly what information remains in your personal knowledge base. Warning This is a warning admonition. Warning: Editing Source Documents Does Not Update Your Database Be aware that if you edit the source documents in your docs folder, these changes will not automatically appear in your database or affect your AI query results. This is a deliberate architectural design decision in Archivist. When you upload a document, Archivist processes it into chunks and stores these chunks in the database\u2014this processed version is what the AI uses to answer your questions. If you later make changes to the source document: Your edits will be saved to the source file, however, the AI will continue using the original, unmodified chunks in the database Your queries will return answers based on the original content, not your updated version To update content in your database: Delete the outdated file using the Delete Selected File button Upload the updated version through the Upload Tab This creates fresh chunks based on your latest content This approach ensures database integrity and gives you explicit control over when content updates occur, preventing accidental or unauthorized changes to your knowledge base.","title":"Browse Tab"},{"location":"tabs/browse/#overview","text":"The Browse Tab serves as your file management center, providing a clear view of all files currently stored in your Archivist database. Once you've uploaded documents through the Upload Tab, this interface allows you to see your complete knowledge collection at a glance. Here you can explore your files and manage your personal knowledge base. The Browse Tab gives you visibility into exactly what information the AI can access when answering your questions, helping you maintain an organized and effective document collection.","title":"Overview"},{"location":"tabs/browse/#details","text":"","title":"Details"},{"location":"tabs/browse/#file-information-display","text":"When you load files from your database, they appear in an organized data frame showing important details about each document\u2014including filename, number of chunks created, and which file sets each document belongs to. This at-a-glance view helps you understand how your knowledge base is structured.","title":"File Information Display"},{"location":"tabs/browse/#search-and-filter","text":"Located above the data frame, a filter option lets you quickly locate specific files by typing part of a filename. As you type, the display automatically narrows to show only matching documents, making it easy to find exactly what you need in larger collections.","title":"Search and Filter"},{"location":"tabs/browse/#file-selection-and-operations","text":"Click on any row in the data frame to select an individual file. Once selected, you can perform various operations using the buttons at the bottom of the tab:","title":"File Selection and Operations"},{"location":"tabs/browse/#open-selected-file-button","text":"This valuable feature opens the original source document that was uploaded to Archivist. When you upload files, Archivist automatically stores a copy of the original in your user data directory. This means you can always reference the complete, original document to verify information or check context when reviewing AI responses. This [[Transparency]] allows you to easily validate answers against their source material with just a click.","title":"Open Selected File Button"},{"location":"tabs/browse/#open-docs-folder-button","text":"This convenient shortcut opens the system folder containing all your source documents. Instead of navigating through numerous directories to find your files, this button takes you directly to the location where Archivist stores all original document copies. This makes it easy to access, organize, or back up your entire document collection at once, saving you time when you need to work with multiple files outside of Archivist.","title":"Open Docs Folder Button"},{"location":"tabs/browse/#clean-up-orphaned-files-button","text":"Sometimes files may appear in your documents folder without properly associated database entries\u2014perhaps from manually copying files to the directory or from interrupted processing operations. The Clean Up button scans your document directory for these \"orphaned\" files (source documents that don't have corresponding chunks in the database) and removes them. This maintenance feature helps keep your document storage clean and properly synchronized with the database, ensuring everything you see is fully functional within Archivist.","title":"Clean Up Orphaned Files Button"},{"location":"tabs/browse/#delete-selected-file-button","text":"When you need to remove a document from your knowledge base, select it in the data frame and click this button. Archivist thoroughly cleans up by removing both the original source document from your docs folder and all associated text chunks from the database. This complete removal ensures no fragments remain to potentially appear in future AI responses, giving you full control over exactly what information remains in your personal knowledge base. Warning This is a warning admonition.","title":"Delete Selected File Button"},{"location":"tabs/browse/#warning-editing-source-documents-does-not-update-your-database","text":"Be aware that if you edit the source documents in your docs folder, these changes will not automatically appear in your database or affect your AI query results. This is a deliberate architectural design decision in Archivist. When you upload a document, Archivist processes it into chunks and stores these chunks in the database\u2014this processed version is what the AI uses to answer your questions. If you later make changes to the source document: Your edits will be saved to the source file, however, the AI will continue using the original, unmodified chunks in the database Your queries will return answers based on the original content, not your updated version To update content in your database: Delete the outdated file using the Delete Selected File button Upload the updated version through the Upload Tab This creates fresh chunks based on your latest content This approach ensures database integrity and gives you explicit control over when content updates occur, preventing accidental or unauthorized changes to your knowledge base.","title":"Warning: Editing Source Documents Does Not Update Your Database"},{"location":"tabs/help_and_licensing/","text":"The Help and Licensing Tab serves as your gateway to additional resources and premium features, providing easy access to both comprehensive documentation and license management tools. Documentation Access Need assistance with Archivist? The Documentation button connects you directly to our online knowledge base, where you'll find detailed guides, tutorials, and tips for getting the most out of every feature. This continually updated resource helps both new and experienced users navigate Archivist's capabilities and solve common questions without waiting for support. License Management The licensing section offers streamlined tools for activating and managing your premium Archivist experience: Purchase License Button Ready to unlock Archivist's paid features? This button opens a secure Stripe payment window where you can purchase your license using any major credit card or payment method. After completing your purchase, you'll automatically receive an email containing your unique license key. License Activation Once you have your license key, simply enter it along with the email address used during purchase into the provided fields and click Activate. The system will verify your credentials online and immediately unlock premium features, including the ability to upload and manage custom AI models. License Deactivation Planning to stop using Archivist on your current device? The Deactivate License button helps you manage your license limits by freeing up a license slot. After deactivation, you can activate the license on another machine while maintaining your remaining activations elsewhere.","title":"Help and Licensing Tab"},{"location":"tabs/help_and_licensing/#documentation-access","text":"Need assistance with Archivist? The Documentation button connects you directly to our online knowledge base, where you'll find detailed guides, tutorials, and tips for getting the most out of every feature. This continually updated resource helps both new and experienced users navigate Archivist's capabilities and solve common questions without waiting for support.","title":"Documentation Access"},{"location":"tabs/help_and_licensing/#license-management","text":"The licensing section offers streamlined tools for activating and managing your premium Archivist experience: Purchase License Button Ready to unlock Archivist's paid features? This button opens a secure Stripe payment window where you can purchase your license using any major credit card or payment method. After completing your purchase, you'll automatically receive an email containing your unique license key. License Activation Once you have your license key, simply enter it along with the email address used during purchase into the provided fields and click Activate. The system will verify your credentials online and immediately unlock premium features, including the ability to upload and manage custom AI models. License Deactivation Planning to stop using Archivist on your current device? The Deactivate License button helps you manage your license limits by freeing up a license slot. After deactivation, you can activate the license on another machine while maintaining your remaining activations elsewhere.","title":"License Management"},{"location":"tabs/inspect/","text":"Overview The Inspect Tab provides granular visibility and control over the individual text chunks that make up your knowledge base. While the Browse Tab focuses on entire documents, the Inspect Tab lets you examine and manage the specific segments that Archivist uses when answering your questions. By examining individual chunks, you can verify exactly what content is available to the AI when it answers your questions, helping you understand and predict its responses based on the specific information segments in your database. The Inspect Tab essentially gives you a \"behind the scenes\" view of how Archivist organizes information, providing transparency and control over the fundamental building blocks of your personal knowledge base. Details File and File Set Dropdowns At the top of the Inspect Tab, you'll find dropdown menus that let you precisely target which chunks to view. You can select a specific file to examine only its chunks, or choose an entire file set to see chunks across multiple documents. This flexibility allows you to focus on exactly the content segments you need to work with. Chunk Data Display After selecting your target file or file set and clicking Load, a detailed data frame appears showing individual chunks from your selection. Each row represents a single chunk with important metadata, giving you [[Transparency]] into exactly how your documents have been processed and organized for AI retrieval. Chunk Management Operations The Inspect Tab empowers you with several important chunk management capabilities: Add Chunks to File Sets You can add selected chunks to specific file sets, attaching labels that logically group content across different documents. This organizational feature lets you categorize information by topic, project, or any system that makes sense for your needs. Need a new category? You can create entirely new file sets directly from this interface and immediately assign chunks to them. This dynamic organization system evolves with your needs, allowing you to continuously refine how your knowledge is structured. Delete Chunks from File Sets Delete Selected Chunks The Delete button gives you precise control over which specific chunks remain in your database. You can use this feature at different scales: Delete chunks that no longer serve your needs Remove all chunks from an entire file by selecting them all at once Clear out entire file sets worth of chunks in a single operation When you delete the last chunk associated with a particular source file, Archivist automatically removes the corresponding source document from your docs folder, maintaining synchronization between your chunks and source files without additional effort. Export to CSV Button This powerful [[Data Portability]] feature lets you export your selected chunks to a standard comma-separated values (CSV) file that opens in Excel, Google Sheets, or any spreadsheet program. This export capability serves several valuable purposes: Create backups of your processed chunks for safekeeping Transfer your carefully curated chunks to other systems or applications Share specific knowledge collections with colleagues (without sharing your entire database) Modify chunks externally and then re-import them using the CSV upload method The export feature completes Archivist's commitment to data portability, ensuring that the work you put into processing and organizing your information isn't locked into a single system. You can use Archivist to ingest documents, carefully segment and organize the information into optimized chunks, and then freely take that processed data with you\u2014whether for archiving, sharing, or use in complementary AI tools.","title":"Inspect Tab"},{"location":"tabs/inspect/#overview","text":"The Inspect Tab provides granular visibility and control over the individual text chunks that make up your knowledge base. While the Browse Tab focuses on entire documents, the Inspect Tab lets you examine and manage the specific segments that Archivist uses when answering your questions. By examining individual chunks, you can verify exactly what content is available to the AI when it answers your questions, helping you understand and predict its responses based on the specific information segments in your database. The Inspect Tab essentially gives you a \"behind the scenes\" view of how Archivist organizes information, providing transparency and control over the fundamental building blocks of your personal knowledge base.","title":"Overview"},{"location":"tabs/inspect/#details","text":"","title":"Details"},{"location":"tabs/inspect/#file-and-file-set-dropdowns","text":"At the top of the Inspect Tab, you'll find dropdown menus that let you precisely target which chunks to view. You can select a specific file to examine only its chunks, or choose an entire file set to see chunks across multiple documents. This flexibility allows you to focus on exactly the content segments you need to work with.","title":"File and File Set Dropdowns"},{"location":"tabs/inspect/#chunk-data-display","text":"After selecting your target file or file set and clicking Load, a detailed data frame appears showing individual chunks from your selection. Each row represents a single chunk with important metadata, giving you [[Transparency]] into exactly how your documents have been processed and organized for AI retrieval.","title":"Chunk Data Display"},{"location":"tabs/inspect/#chunk-management-operations","text":"The Inspect Tab empowers you with several important chunk management capabilities:","title":"Chunk Management Operations"},{"location":"tabs/inspect/#add-chunks-to-file-sets","text":"You can add selected chunks to specific file sets, attaching labels that logically group content across different documents. This organizational feature lets you categorize information by topic, project, or any system that makes sense for your needs. Need a new category? You can create entirely new file sets directly from this interface and immediately assign chunks to them. This dynamic organization system evolves with your needs, allowing you to continuously refine how your knowledge is structured.","title":"Add Chunks to File Sets"},{"location":"tabs/inspect/#delete-chunks-from-file-sets","text":"","title":"Delete Chunks from File Sets"},{"location":"tabs/inspect/#delete-selected-chunks","text":"The Delete button gives you precise control over which specific chunks remain in your database. You can use this feature at different scales: Delete chunks that no longer serve your needs Remove all chunks from an entire file by selecting them all at once Clear out entire file sets worth of chunks in a single operation When you delete the last chunk associated with a particular source file, Archivist automatically removes the corresponding source document from your docs folder, maintaining synchronization between your chunks and source files without additional effort.","title":"Delete Selected Chunks"},{"location":"tabs/inspect/#export-to-csv-button","text":"This powerful [[Data Portability]] feature lets you export your selected chunks to a standard comma-separated values (CSV) file that opens in Excel, Google Sheets, or any spreadsheet program. This export capability serves several valuable purposes: Create backups of your processed chunks for safekeeping Transfer your carefully curated chunks to other systems or applications Share specific knowledge collections with colleagues (without sharing your entire database) Modify chunks externally and then re-import them using the CSV upload method The export feature completes Archivist's commitment to data portability, ensuring that the work you put into processing and organizing your information isn't locked into a single system. You can use Archivist to ingest documents, carefully segment and organize the information into optimized chunks, and then freely take that processed data with you\u2014whether for archiving, sharing, or use in complementary AI tools.","title":"Export to CSV Button"},{"location":"tabs/pre-process/","text":"Overview The Pre-process Tab provides a powerful tool for preparing your documents for AI interaction. This optional feature converts various file formats into plain text that's optimized for use with language models. This versatile preprocessing feature serves multiple purposes\u2014it helps prepare documents for upload into your Archivist database for RAG conversations, but also supports interoperability with other AI platforms. You can convert documents here and then use the resulting text files wherever you need them, making Archivist a valuable tool in your broader AI workflow. This could be a step in the upload process. But keeping it separate gives the user the option to quickly convert a portion to text and then gives them the option of whether to upload the whole thing or maybe they want to extract or add splitting tokens. It's another sacrifice of convenience that we think gives them more control. Document Input Upload documents in different formats\u2014PDF, DOCX, images with text, and more\u2014to convert them into AI-ready text. Behind the scenes, Archivist uses the robust [[IBM Docling]] program to handle the conversion process accurately. Processing Modes Use Docling + Vision Language Model (VLM) to generate text descriptions of pictures in the processed documents. This is as opposed to separating the images, using a vision embedding model, and maintaining a parallel set of embeddings, as well as having to manage the many image files. It is a midpoint in rigor between ignoring the images and intensive processing. By choosing this method we are also able to use a visual processing model which is adapted to llama-cpp-python/gguf. Text Output Once conversion is complete, the extracted text appears in a visual display area where you can review. There are a few options for what to do with your converted text: Save as Text: Export the content as a simple .txt file Save as Markdown: Export the content as a .md file, preserving basic formatting Copy to Clipboard: Quickly copy the entire text to paste elsewhere See Also [[Privacy]] [[Data Portability]] [[Transparency]]","title":"Pre-Process Tab"},{"location":"tabs/pre-process/#overview","text":"The Pre-process Tab provides a powerful tool for preparing your documents for AI interaction. This optional feature converts various file formats into plain text that's optimized for use with language models. This versatile preprocessing feature serves multiple purposes\u2014it helps prepare documents for upload into your Archivist database for RAG conversations, but also supports interoperability with other AI platforms. You can convert documents here and then use the resulting text files wherever you need them, making Archivist a valuable tool in your broader AI workflow. This could be a step in the upload process. But keeping it separate gives the user the option to quickly convert a portion to text and then gives them the option of whether to upload the whole thing or maybe they want to extract or add splitting tokens. It's another sacrifice of convenience that we think gives them more control.","title":"Overview"},{"location":"tabs/pre-process/#document-input","text":"Upload documents in different formats\u2014PDF, DOCX, images with text, and more\u2014to convert them into AI-ready text. Behind the scenes, Archivist uses the robust [[IBM Docling]] program to handle the conversion process accurately.","title":"Document Input"},{"location":"tabs/pre-process/#processing-modes","text":"Use Docling + Vision Language Model (VLM) to generate text descriptions of pictures in the processed documents. This is as opposed to separating the images, using a vision embedding model, and maintaining a parallel set of embeddings, as well as having to manage the many image files. It is a midpoint in rigor between ignoring the images and intensive processing. By choosing this method we are also able to use a visual processing model which is adapted to llama-cpp-python/gguf.","title":"Processing Modes"},{"location":"tabs/pre-process/#text-output","text":"Once conversion is complete, the extracted text appears in a visual display area where you can review. There are a few options for what to do with your converted text: Save as Text: Export the content as a simple .txt file Save as Markdown: Export the content as a .md file, preserving basic formatting Copy to Clipboard: Quickly copy the entire text to paste elsewhere","title":"Text Output"},{"location":"tabs/pre-process/#see-also","text":"[[Privacy]] [[Data Portability]] [[Transparency]]","title":"See Also"},{"location":"tabs/query/","text":"Overview The Query Tab is the heart of Archivist, greeting you when you first open the application. This friendly chat interface is where all your AI conversations happen. Here, you can freely chat with the AI about any topic, ask questions about your uploaded documents, or explore ideas combining both general knowledge and your personal files. The clean, intuitive design makes it easy to type your questions, see responses in real-time, and switch between different types of AI chats\u2014whether you're having a general conversation or diving deep into specific documents from your collection. It's your command center for interacting with both the AI and your personal knowledge library. Details Files and File Sets Dropdowns At the top of the Query Tab, you'll find two important dropdown menus that help you control which documents the AI uses when answering your questions. File Dropdown: This first dropdown lets you select specific individual files to chat with. Want to focus your conversation on just your quarterly report or that research paper you uploaded? Simply select it from this dropdown, and Archivist will limit its responses to information contained in that specific document. File Set Dropdown: The second dropdown allows you to work with groups of related files called \"file sets.\" File sets are logical groupings of documents that you've organized together\u2014perhaps all documents related to a particular project, topic, or client. Every document is automatically included in the default \"All Docs\" file set, which cannot be removed. This ensures you can always query your entire document collection at once if needed. When you first launch Archivist, your document database will be empty, so these dropdowns won't contain any options until you upload your first files. Query Interface Active Model Display At the top of the chat interface, a text indicator shows you which AI model is currently active. Paid users can upload and switch between different AI models, and this display helps you keep track of which one you're currently using. General Query Button This button allows you to have a direct conversation with the AI without referencing any of your personal documents. When you click \"General Query,\" the chat switches to a standard AI conversation mode, drawing only on the model's built-in knowledge rather than your document database. Export Chat Privacy is important in Archivist, so your conversations aren't stored permanently. The \"Export Session\" button lets you save your current conversation as a text file that you can download. This feature gives you several options: save important conversations for your records, transfer them to other applications, or even re-upload them as documents into your Archivist database to reference in future RAG discussions. Chat Display Window The main chat area displays your ongoing conversation with the AI. As you chat, your messages and the AI's responses appear in this window, creating a readable dialogue. Each message includes helpful options like a copy button to easily save specific responses to your clipboard. Message Input Box Located at the bottom of the screen, this text box is where you type your questions or messages to the AI. It's designed to be simple and intuitive\u2014just click inside, type your message, and you're ready to send. Send Button: Next to the input box, the Send button transmits your message to the AI model, triggering it to process your question and generate a response based on your selected files or general knowledge. Stop Generation Button If the AI is providing a lengthy response that you'd like to cut short, the Stop Generation button immediately halts the AI's output. This gives you control over the conversation flow and helps when you've already received the information you need. Clear Chat Button When you want to start fresh, the Delete Chat button allows you to completely reset your conversation, removing all previous messages and beginning a new dialogue with the AI. Voice Input Voice Recording Component Below the main chat interface, you'll find a convenient voice transcription card that allows you to speak your messages rather than type them. Simply click the Record button to begin capturing your voice\u2014you may need to grant microphone permission to use this feature. When you've finished speaking, click Stop Recording to end the audio capture. Send to Textbox Button After recording, you can click this button to have your spoken words transcribed into text and placed in the message input box. This two-step process gives you the opportunity to review the transcription for accuracy and make any necessary edits before sending it to the AI. Send to AI Button For a more streamlined experience, this button transcribes your recorded audio and immediately sends it to the AI model, bypassing the input box entirely. Your transcribed message will appear in the chat window as your message, followed directly by the AI's response. This option is perfect when you're confident in the transcription quality and want quick results. See Also [[00 - Overview]] [[Pre-Process Tab]]","title":"Query Tab"},{"location":"tabs/query/#overview","text":"The Query Tab is the heart of Archivist, greeting you when you first open the application. This friendly chat interface is where all your AI conversations happen. Here, you can freely chat with the AI about any topic, ask questions about your uploaded documents, or explore ideas combining both general knowledge and your personal files. The clean, intuitive design makes it easy to type your questions, see responses in real-time, and switch between different types of AI chats\u2014whether you're having a general conversation or diving deep into specific documents from your collection. It's your command center for interacting with both the AI and your personal knowledge library.","title":"Overview"},{"location":"tabs/query/#details","text":"","title":"Details"},{"location":"tabs/query/#files-and-file-sets-dropdowns","text":"At the top of the Query Tab, you'll find two important dropdown menus that help you control which documents the AI uses when answering your questions. File Dropdown: This first dropdown lets you select specific individual files to chat with. Want to focus your conversation on just your quarterly report or that research paper you uploaded? Simply select it from this dropdown, and Archivist will limit its responses to information contained in that specific document. File Set Dropdown: The second dropdown allows you to work with groups of related files called \"file sets.\" File sets are logical groupings of documents that you've organized together\u2014perhaps all documents related to a particular project, topic, or client. Every document is automatically included in the default \"All Docs\" file set, which cannot be removed. This ensures you can always query your entire document collection at once if needed. When you first launch Archivist, your document database will be empty, so these dropdowns won't contain any options until you upload your first files.","title":"Files and File Sets Dropdowns"},{"location":"tabs/query/#query-interface","text":"","title":"Query Interface"},{"location":"tabs/query/#active-model-display","text":"At the top of the chat interface, a text indicator shows you which AI model is currently active. Paid users can upload and switch between different AI models, and this display helps you keep track of which one you're currently using.","title":"Active Model Display"},{"location":"tabs/query/#general-query-button","text":"This button allows you to have a direct conversation with the AI without referencing any of your personal documents. When you click \"General Query,\" the chat switches to a standard AI conversation mode, drawing only on the model's built-in knowledge rather than your document database.","title":"General Query Button"},{"location":"tabs/query/#export-chat","text":"Privacy is important in Archivist, so your conversations aren't stored permanently. The \"Export Session\" button lets you save your current conversation as a text file that you can download. This feature gives you several options: save important conversations for your records, transfer them to other applications, or even re-upload them as documents into your Archivist database to reference in future RAG discussions.","title":"Export Chat"},{"location":"tabs/query/#chat-display-window","text":"The main chat area displays your ongoing conversation with the AI. As you chat, your messages and the AI's responses appear in this window, creating a readable dialogue. Each message includes helpful options like a copy button to easily save specific responses to your clipboard.","title":"Chat Display Window"},{"location":"tabs/query/#message-input-box","text":"Located at the bottom of the screen, this text box is where you type your questions or messages to the AI. It's designed to be simple and intuitive\u2014just click inside, type your message, and you're ready to send.","title":"Message Input Box"},{"location":"tabs/query/#send-button","text":"Next to the input box, the Send button transmits your message to the AI model, triggering it to process your question and generate a response based on your selected files or general knowledge.","title":"Send Button:"},{"location":"tabs/query/#stop-generation-button","text":"If the AI is providing a lengthy response that you'd like to cut short, the Stop Generation button immediately halts the AI's output. This gives you control over the conversation flow and helps when you've already received the information you need.","title":"Stop Generation Button"},{"location":"tabs/query/#clear-chat-button","text":"When you want to start fresh, the Delete Chat button allows you to completely reset your conversation, removing all previous messages and beginning a new dialogue with the AI.","title":"Clear Chat Button"},{"location":"tabs/query/#voice-input","text":"","title":"Voice Input"},{"location":"tabs/query/#voice-recording-component","text":"Below the main chat interface, you'll find a convenient voice transcription card that allows you to speak your messages rather than type them. Simply click the Record button to begin capturing your voice\u2014you may need to grant microphone permission to use this feature. When you've finished speaking, click Stop Recording to end the audio capture.","title":"Voice Recording Component"},{"location":"tabs/query/#send-to-textbox-button","text":"After recording, you can click this button to have your spoken words transcribed into text and placed in the message input box. This two-step process gives you the opportunity to review the transcription for accuracy and make any necessary edits before sending it to the AI.","title":"Send to Textbox Button"},{"location":"tabs/query/#send-to-ai-button","text":"For a more streamlined experience, this button transcribes your recorded audio and immediately sends it to the AI model, bypassing the input box entirely. Your transcribed message will appear in the chat window as your message, followed directly by the AI's response. This option is perfect when you're confident in the transcription quality and want quick results.","title":"Send to AI Button"},{"location":"tabs/query/#see-also","text":"[[00 - Overview]] [[Pre-Process Tab]]","title":"See Also"},{"location":"tabs/upload/","text":"Overview The Upload Tab is where you expand your personal knowledge database by adding documents for Archivist to learn from. This straightforward interface allows you to directly upload files that will be processed, understood, and made available for your AI conversations. There's no need to use the Pre-Processing Tab first\u2014though that option remains available if you want extra control\u2014as Archivist can handle your documents directly from this interface, automatically preparing them for AI interaction and storing them in your private database for immediate use in your queries. Text Splitting Methods Fixed Chunk Size Method This straightforward approach divides your document into sections of consistent length. You can customize both the chunk size (how many characters or tokens appear in each section) and chunk overlap (how much content repeats between adjacent chunks). This method works well for most general documents where you want reliable, consistent processing without manual intervention. CSV Row-Based Method For maximum precision, you can upload a CSV file where each row contains a pre-defined chunk of text. This powerful option lets you prepare your content exactly as you want it divided\u2014perhaps breaking at logical topic changes or keeping related concepts together. Though it requires more preparation, this method gives you complete control over chunk boundaries, allowing you to organize information optimally for your specific needs. Simply place your text chunks in column A of your spreadsheet, save as CSV, and upload. ==The CSV method supports [[Data Portability]] by enabling users to...== Custom Delimiter Method This flexible approach lets you upload a text file where you've inserted special character patterns (delimiters) at points where you want the text split into chunks. For example, you might use \"###\" or \"---\" between sections of a document. When uploading, you'll specify which delimiter pattern you've used, and Archivist will create chunks precisely at those boundaries. This balance between automation and control is perfect for when you want to split content at logical breakpoints without the manual work of creating a CSV. Notes By default, all documents are split into chunks and the chunks are labeled with metadata indicating the name of the source file and all chunks are added to the [[File Sets|File Set]] \"All Docs\". At the time of upload, users can specify whether they want to add the uploaded document to an existing File Set, to create a new File Set, or not add it to any File Set (other than \"All Docs\"). At the time of upload, a copy of the source file is created in a user data directory to facilitate [[Transparency]] by enabling users to have quick access to source data to validate information coming back from the AI model.","title":"Upload Tab"},{"location":"tabs/upload/#overview","text":"The Upload Tab is where you expand your personal knowledge database by adding documents for Archivist to learn from. This straightforward interface allows you to directly upload files that will be processed, understood, and made available for your AI conversations. There's no need to use the Pre-Processing Tab first\u2014though that option remains available if you want extra control\u2014as Archivist can handle your documents directly from this interface, automatically preparing them for AI interaction and storing them in your private database for immediate use in your queries.","title":"Overview"},{"location":"tabs/upload/#text-splitting-methods","text":"","title":"Text Splitting Methods"},{"location":"tabs/upload/#fixed-chunk-size-method","text":"This straightforward approach divides your document into sections of consistent length. You can customize both the chunk size (how many characters or tokens appear in each section) and chunk overlap (how much content repeats between adjacent chunks). This method works well for most general documents where you want reliable, consistent processing without manual intervention.","title":"Fixed Chunk Size Method"},{"location":"tabs/upload/#csv-row-based-method","text":"For maximum precision, you can upload a CSV file where each row contains a pre-defined chunk of text. This powerful option lets you prepare your content exactly as you want it divided\u2014perhaps breaking at logical topic changes or keeping related concepts together. Though it requires more preparation, this method gives you complete control over chunk boundaries, allowing you to organize information optimally for your specific needs. Simply place your text chunks in column A of your spreadsheet, save as CSV, and upload. ==The CSV method supports [[Data Portability]] by enabling users to...==","title":"CSV Row-Based Method"},{"location":"tabs/upload/#custom-delimiter-method","text":"This flexible approach lets you upload a text file where you've inserted special character patterns (delimiters) at points where you want the text split into chunks. For example, you might use \"###\" or \"---\" between sections of a document. When uploading, you'll specify which delimiter pattern you've used, and Archivist will create chunks precisely at those boundaries. This balance between automation and control is perfect for when you want to split content at logical breakpoints without the manual work of creating a CSV.","title":"Custom Delimiter Method"},{"location":"tabs/upload/#notes","text":"By default, all documents are split into chunks and the chunks are labeled with metadata indicating the name of the source file and all chunks are added to the [[File Sets|File Set]] \"All Docs\". At the time of upload, users can specify whether they want to add the uploaded document to an existing File Set, to create a new File Set, or not add it to any File Set (other than \"All Docs\"). At the time of upload, a copy of the source file is created in a user data directory to facilitate [[Transparency]] by enabling users to have quick access to source data to validate information coming back from the AI model.","title":"Notes"}]}